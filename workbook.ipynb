{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08138342",
   "metadata": {},
   "source": [
    "Workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ee6657f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ef978da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader     #need to seperate text into words and sentences\n",
    "from nltk.probability import FreqDist     #need to do frequency calculations\n",
    "from nltk.collocations import BigramCollocationFinder     #need to find collocations\n",
    "from nltk.stem.snowball import SnowballStemmer     #used to stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "80cd432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load texts\n",
    "corpusDirectory = \"./Corpus_Data\"\n",
    "corpus = PlaintextCorpusReader(corpusDirectory, \".*\")\n",
    "\n",
    "#load texts into nltk word list, this includes punctuation \n",
    "#punctuation is treated as a word in these lists!\n",
    "\n",
    "chomskyWords = corpus.words(\"ChomskyInterview.txt\")\n",
    "eurogamerWords = corpus.words(\"Eurogamer_Corpus.txt\")\n",
    "wozWords = corpus.words(\"WOZScript.txt\")\n",
    "\n",
    "#text divided into sentences\n",
    "chomskySents = corpus.sents(\"ChomskyInterview.txt\")\n",
    "euroSents = corpus.sents(\"Eurogamer_Corpus.txt\")\n",
    "wozSents = corpus.sents(\"WOzScript.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "aabab954",
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequency dist for words beginning with vowels\n",
    "\n",
    "def startvowelfreq(corpus):\n",
    "    \n",
    "    #create a list for each vowel\n",
    "    wordA = []\n",
    "    wordE = []\n",
    "    wordI = []\n",
    "    wordO = []\n",
    "    wordU = []\n",
    "    \n",
    "    wordVowel = [wordA, wordE, wordI, wordO, wordU]     #put all the vowel lists in single list\n",
    "    \n",
    "    for word in corpus:      #find words beginning with the vowel, add the lower case version to the corresponding list\n",
    "        if re.search(\"^[aA]\", word):\n",
    "            wordA.append(word.lower())\n",
    "            \n",
    "        elif re.search(\"^[eE]\", word):\n",
    "            wordE.append(word.lower())\n",
    "            \n",
    "        elif re.search(\"^[iI]\", word):\n",
    "            wordI.append(word.lower())\n",
    "            \n",
    "        elif re.search(\"^[oO]\", word):\n",
    "            wordO.append(word.lower())\n",
    "            \n",
    "        elif re.search(\"^[uU]\", word):\n",
    "            wordU.append(word.lower())\n",
    "\n",
    "    for vowel in wordVowel:         # for each vowel list, run FreqDist to get frequency, and then print the top 10\n",
    "        vowelFreq = FreqDist(vowel)\n",
    "        vowelTop10 = vowelFreq.most_common(10)\n",
    "        print(vowelTop10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "644c35cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 267), ('and', 217), ('are', 72), ('about', 68), ('as', 46), ('at', 29), ('all', 28), ('an', 27), ('any', 19), ('american', 15)]\n",
      "[('ezra', 35), ('even', 15), ('example', 7), ('every', 7), ('end', 6), ('early', 6), ('economic', 6), ('everything', 6), ('ever', 5), ('essentially', 5)]\n",
      "[('it', 261), ('in', 188), ('is', 158), ('i', 153), ('if', 54), ('into', 19), ('industry', 14), ('idea', 8), ('international', 7), ('its', 6)]\n",
      "[('of', 356), ('on', 55), ('or', 31), ('one', 31), ('out', 31), ('our', 24), ('other', 18), ('over', 16), ('own', 12), ('others', 7)]\n",
      "[('up', 18), ('us', 16), ('united', 8), ('used', 7), ('under', 7), ('understand', 6), ('use', 5), ('u', 5), ('using', 4), ('unfortunately', 4)]\n"
     ]
    }
   ],
   "source": [
    "startvowelfreq(chomskyWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6c5dd3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 183), ('and', 175), ('an', 37), ('as', 33), ('are', 30), ('at', 20), ('all', 15), ('army', 10), ('about', 9), ('also', 8)]\n",
      "[('engage', 18), ('even', 15), ('each', 14), ('every', 13), ('estelle', 10), ('emblem', 10), ('enemy', 6), ('end', 5), ('entirely', 4), ('enemies', 4)]\n",
      "[('in', 78), ('it', 70), ('i', 69), ('is', 56), ('its', 21), ('into', 18), ('if', 18), ('inkulinati', 13), ('instead', 7), ('isn', 7)]\n",
      "[('of', 125), ('or', 24), ('on', 19), ('one', 18), ('off', 16), ('out', 15), ('over', 13), ('other', 10), ('own', 8), ('only', 7)]\n",
      "[('up', 16), ('unbound', 11), ('units', 9), ('unique', 5), ('until', 4), ('unit', 3), ('unless', 2), ('underneath', 2), ('used', 2), ('upon', 2)]\n"
     ]
    }
   ],
   "source": [
    "startvowelfreq(eurogamerWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "dc17a12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('and', 768), ('as', 344), ('a', 331), ('at', 167), ('all', 115), ('aunt', 69), ('about', 66), ('are', 64), ('away', 52), ('around', 40)]\n",
      "[('em', 101), ('els', 43), ('exits', 32), ('enters', 26), ('ever', 23), ('enter', 23), ('eyes', 22), ('exit', 19), ('emerald', 14), ('even', 12)]\n",
      "[('i', 474), ('in', 360), ('it', 261), ('is', 102), ('into', 72), ('if', 58), ('int', 30), ('isn', 9), ('images', 6), ('incubator', 5)]\n",
      "[('of', 449), ('oh', 278), ('on', 233), ('o', 225), ('out', 158), ('oz', 128), ('over', 59), ('one', 40), ('others', 37), ('old', 32)]\n",
      "[('up', 181), ('uncle', 45), ('us', 27), ('under', 17), ('use', 6), ('uh', 5), ('upon', 3), ('until', 3), ('used', 2), ('ugly', 2)]\n"
     ]
    }
   ],
   "source": [
    "startvowelfreq(wozWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "33341564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11165\n",
      "5858\n",
      "29996\n"
     ]
    }
   ],
   "source": [
    "#number of words\n",
    "\n",
    "def num_words(corpus):      #returns the number of words without punctuation\n",
    "    \n",
    "    actualwords = []\n",
    "    \n",
    "    for word in corpus:     #only include words that begin with a letter\n",
    "        if re.search(\"^[A-Za-z]\", word):\n",
    "            actualwords.append(word)\n",
    "            \n",
    "    numwords = len(actualwords)\n",
    "    \n",
    "    return numwords\n",
    "\n",
    "\n",
    "\n",
    "print(num_words(chomskyWords))\n",
    "\n",
    "print(num_words(eurogamerWords))\n",
    "\n",
    "print(num_words(wozWords))\n",
    "\n",
    "\n",
    "chomskyWordsactual = num_words(chomskyWords)\n",
    "euroWordsactual = num_words(eurogamerWords)\n",
    "wozWordsactual = num_words(wozWords)\n",
    "#these word lists don't include punctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4c980f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lexical diversity\n",
    "\n",
    "def lexical_diversity(text):\n",
    "    return len(set(text)) / len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "838970b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1660031548110869"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(chomskyWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "85e0c712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29085392284351974"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(eurogamerWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5757cf1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07287356905348123"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(wozWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cd8f1076",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collocation finder\n",
    "\n",
    "def collocationfinder(corpus):\n",
    "  \n",
    "    bigram_measures = nltk.collocations.BigramAssocMeasures()     #import bigram finder\n",
    "    \n",
    "    collocater = BigramCollocationFinder.from_words(corpus)     #set up finder to search text\n",
    "    \n",
    "    #filter out meaningless associations\n",
    "    collocater.apply_word_filter(lambda w: w in (\"'\", ',',\".\",\"re\",\"?\",\"!\",\"nt\",\"â€™\",\":\",\"--\",\"S\"))   \n",
    "    \n",
    "    print (collocater.nbest(bigram_measures.likelihood_ratio, 10))     #print top ten bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c658a475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('EZRA', 'KLEIN'), ('NOAM', 'CHOMSKY'), ('going', 'to'), ('I', 'think'), ('in', 'the'), ('of', 'the'), ('a', 'lot'), ('I', 'mean'), ('United', 'States'), ('I', 'don')]\n"
     ]
    }
   ],
   "source": [
    "collocationfinder(chomskyWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "80c489a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', 'Space'), ('Fire', 'Emblem'), ('Space', 'for'), ('the', 'Unbound'), ('This', 'is'), ('even', 'if'), ('Three', 'Houses'), ('for', 'the'), ('Emblem', 'Engage'), ('you', 'can')]\n"
     ]
    }
   ],
   "source": [
    "collocationfinder(eurogamerWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "00639f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Tin', 'Man'), ('TIN', 'MAN'), ('CAMERA', 'PANS'), ('CAMERA', 'TRUCKS'), ('DOROTHY', 'Oh'), ('Aunt', 'Em'), ('LAP', 'DISSOLVE'), ('DISSOLVE', 'TO'), ('shooting', 'past'), ('Dorothy', 'and')]\n"
     ]
    }
   ],
   "source": [
    "collocationfinder(wozWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9ab3695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#longest sentence\n",
    "\n",
    "def longsent(sentcorpus):     #prints info about longsent, num and joined longsent\n",
    "    \n",
    "    sentedit = []\n",
    "\n",
    "    for sent in sentcorpus:\n",
    "        for word in sent:\n",
    "            if re.search(\"[^A-Za-z]\", word):\n",
    "                sent.remove(word)\n",
    "        sentedit.append(sent)\n",
    "        \n",
    "    longsent = max(sentedit, key=len)     #creates a list\n",
    "\n",
    "    print(longsent)\n",
    "    print(len(longsent))\n",
    "\n",
    "    longsent_join = \" \".join(longsent)\n",
    "    print(longsent_join)\n",
    "    \n",
    "    \n",
    "    \n",
    "def longsentvar(sentcorpus):     #used for stemming function, only returns longsent, does not print\n",
    "    \n",
    "    sentedit = []\n",
    "\n",
    "    for sent in sentcorpus:\n",
    "        for word in sent:\n",
    "            if re.search(\"[^A-Za-z]\", word):\n",
    "                sent.remove(word)\n",
    "        sentedit.append(sent)\n",
    "        \n",
    "    longsent = max(sentedit, key=len)     #creates a list\n",
    "    return longsent\n",
    "\n",
    "chomskylong = longsentvar(chomskySents)\n",
    "eurolong = longsentvar(euroSents)\n",
    "wozlong = longsentvar(wozSents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d8e8721b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['If', 'I', 'go', 'back', 'to', 'early', 'childhood', 'some', 'of', 'the', 'reading', 'that', 'had', 'a', 'lasting', 'impact', 'which', 'I', 'don', 't', 'even', 'think', 'it', 's', 'in', 'English', 'was', 'the', 'Hebrew', 'essays', 'of', 'a', 'turn', 'of', 'the', 'century', 'essayist', 'that', 'went', 'by', 'the', 'name', 'of', 'Ahad', 'Ha', 'am', 'writing', 'about', 'partly', 'intellectual', 'contributions', 'which', 'were', 'significant', 'partly', 'talking', 'about', 'the', 'developing', 'situation', 'in', 'what', 'was', 'then', 'Palestine', 'which', 'had', 'a', 'large', 'effect', 'on', 'my', 'thinking', 'ever', 'since']\n",
      "75\n",
      "If I go back to early childhood some of the reading that had a lasting impact which I don t even think it s in English was the Hebrew essays of a turn of the century essayist that went by the name of Ahad Ha am writing about partly intellectual contributions which were significant partly talking about the developing situation in what was then Palestine which had a large effect on my thinking ever since\n"
     ]
    }
   ],
   "source": [
    "longsent(chomskySents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e476e814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['As', 'a', 'surprisingly', 'linear', 'adventure', 'it', 's', 'difficult', 'to', 'talk', 'much', 'about', 'Estelle', 's', 'journey', 'without', 'giving', 'something', 'important', 'away', 'and', 'as', 'her', 'story', 'is', 'essentially', 'as', 'long', 'or', 'as', 'brief', 'as', 'you', 'want', 'it', 'to', 'be', 'you', 'can', 'belt', 'through', 'it', 'and', 'be', 'done', 'within', 'a', 'few', 'hours', 'or', 'savour', 'each', 'new', 'environment', 'and', 'scour', 'every', 'inch', 'of', 'it', 'for', 'days', 'I', 'imagine', 'there', 'may', 'be', 'some', 'people', 'or', 'places', 'you', 'could', 'miss', 'entirely', 'and', 'complete', 'the', 'game', 'never', 'knowing', 'that', 'they', 'existed']\n",
      "84\n",
      "As a surprisingly linear adventure it s difficult to talk much about Estelle s journey without giving something important away and as her story is essentially as long or as brief as you want it to be you can belt through it and be done within a few hours or savour each new environment and scour every inch of it for days I imagine there may be some people or places you could miss entirely and complete the game never knowing that they existed\n"
     ]
    }
   ],
   "source": [
    "longsent(euroSents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6f25c26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gale', 'Sitting', 'room', 'Aunt', 'Em', 'and', 'Miss', 'Gulch', 'seated', 'Dorothy', 'enters', 'carrying', 'Toto', 'in', 'her', 'arms', 'CAMERA', 'TRUCKS', 'forward', 'on', 'them', 'PANS', 'to', 'right', 'with', 'Dorothy', 'to', 'Uncle', 'Henry', 'then', 'Pans', 'her', 'left', 'to', 'Aunt', 'Em', 'and', 'Miss', 'Gulch', 'Miss', 'Gulch', 'shows', 'order', 'to', 'Aunt', 'Em', 'Uncle', 'Henry', 'enters', 'looks', 'at', 'the', 'order', 'Miss', 'Gulch', 'picks', 'up', 'basket', 'rises', 'Dorothy', 'screams', 'at', 'Miss', 'Gulch', 'Miss', 'Gulch', 'tries', 'to', 'take', 'Toto', 'away', 'from', 'Dorothy', 'Uncle', 'Henry', 'takes', 'Toto', 'puts', 'him', 'into', 'basket']\n",
      "81\n",
      "Gale Sitting room Aunt Em and Miss Gulch seated Dorothy enters carrying Toto in her arms CAMERA TRUCKS forward on them PANS to right with Dorothy to Uncle Henry then Pans her left to Aunt Em and Miss Gulch Miss Gulch shows order to Aunt Em Uncle Henry enters looks at the order Miss Gulch picks up basket rises Dorothy screams at Miss Gulch Miss Gulch tries to take Toto away from Dorothy Uncle Henry takes Toto puts him into basket\n"
     ]
    }
   ],
   "source": [
    "longsent(wozSents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0d3d832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def stemming(longsent):\n",
    "    \n",
    "    for word in longsent:\n",
    "        print(stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c6159c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if\n",
      "i\n",
      "go\n",
      "back\n",
      "to\n",
      "earli\n",
      "childhood\n",
      "some\n",
      "of\n",
      "the\n",
      "read\n",
      "that\n",
      "had\n",
      "a\n",
      "last\n",
      "impact\n",
      "which\n",
      "i\n",
      "don\n",
      "t\n",
      "even\n",
      "think\n",
      "it\n",
      "s\n",
      "in\n",
      "english\n",
      "was\n",
      "the\n",
      "hebrew\n",
      "essay\n",
      "of\n",
      "a\n",
      "turn\n",
      "of\n",
      "the\n",
      "centuri\n",
      "essayist\n",
      "that\n",
      "went\n",
      "by\n",
      "the\n",
      "name\n",
      "of\n",
      "ahad\n",
      "ha\n",
      "am\n",
      "write\n",
      "about\n",
      "part\n",
      "intellectu\n",
      "contribut\n",
      "which\n",
      "were\n",
      "signific\n",
      "part\n",
      "talk\n",
      "about\n",
      "the\n",
      "develop\n",
      "situat\n",
      "in\n",
      "what\n",
      "was\n",
      "then\n",
      "palestin\n",
      "which\n",
      "had\n",
      "a\n",
      "larg\n",
      "effect\n",
      "on\n",
      "my\n",
      "think\n",
      "ever\n",
      "sinc\n"
     ]
    }
   ],
   "source": [
    "stemming(chomskylong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "af15c961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as\n",
      "a\n",
      "surpris\n",
      "linear\n",
      "adventur\n",
      "it\n",
      "s\n",
      "difficult\n",
      "to\n",
      "talk\n",
      "much\n",
      "about\n",
      "estell\n",
      "s\n",
      "journey\n",
      "without\n",
      "give\n",
      "someth\n",
      "import\n",
      "away\n",
      "and\n",
      "as\n",
      "her\n",
      "stori\n",
      "is\n",
      "essenti\n",
      "as\n",
      "long\n",
      "or\n",
      "as\n",
      "brief\n",
      "as\n",
      "you\n",
      "want\n",
      "it\n",
      "to\n",
      "be\n",
      "you\n",
      "can\n",
      "belt\n",
      "through\n",
      "it\n",
      "and\n",
      "be\n",
      "done\n",
      "within\n",
      "a\n",
      "few\n",
      "hour\n",
      "or\n",
      "savour\n",
      "each\n",
      "new\n",
      "environ\n",
      "and\n",
      "scour\n",
      "everi\n",
      "inch\n",
      "of\n",
      "it\n",
      "for\n",
      "day\n",
      "i\n",
      "imagin\n",
      "there\n",
      "may\n",
      "be\n",
      "some\n",
      "peopl\n",
      "or\n",
      "place\n",
      "you\n",
      "could\n",
      "miss\n",
      "entir\n",
      "and\n",
      "complet\n",
      "the\n",
      "game\n",
      "never\n",
      "know\n",
      "that\n",
      "they\n",
      "exist\n"
     ]
    }
   ],
   "source": [
    "stemming(eurolong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e9cc9cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gale\n",
      "sit\n",
      "room\n",
      "aunt\n",
      "em\n",
      "and\n",
      "miss\n",
      "gulch\n",
      "seat\n",
      "dorothi\n",
      "enter\n",
      "carri\n",
      "toto\n",
      "in\n",
      "her\n",
      "arm\n",
      "camera\n",
      "truck\n",
      "forward\n",
      "on\n",
      "them\n",
      "pan\n",
      "to\n",
      "right\n",
      "with\n",
      "dorothi\n",
      "to\n",
      "uncl\n",
      "henri\n",
      "then\n",
      "pan\n",
      "her\n",
      "left\n",
      "to\n",
      "aunt\n",
      "em\n",
      "and\n",
      "miss\n",
      "gulch\n",
      "miss\n",
      "gulch\n",
      "show\n",
      "order\n",
      "to\n",
      "aunt\n",
      "em\n",
      "uncl\n",
      "henri\n",
      "enter\n",
      "look\n",
      "at\n",
      "the\n",
      "order\n",
      "miss\n",
      "gulch\n",
      "pick\n",
      "up\n",
      "basket\n",
      "rise\n",
      "dorothi\n",
      "scream\n",
      "at\n",
      "miss\n",
      "gulch\n",
      "miss\n",
      "gulch\n",
      "tri\n",
      "to\n",
      "take\n",
      "toto\n",
      "away\n",
      "from\n",
      "dorothi\n",
      "uncl\n",
      "henri\n",
      "take\n",
      "toto\n",
      "put\n",
      "him\n",
      "into\n",
      "basket\n"
     ]
    }
   ],
   "source": [
    "stemming(wozlong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab35ef5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
